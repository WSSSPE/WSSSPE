\documentclass[11pt, oneside]{amsart}

\usepackage{amsmath}
\usepackage{amssymb}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}

\usepackage{color}
\usepackage{dcolumn}
\usepackage{float}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{rotating}
\usepackage{subfigure}
\usepackage{psfrag}
\usepackage{tabularx}
\usepackage[hyphens]{url}
\usepackage{wrapfig}
\usepackage{enumitem}
\usepackage{multicol}

%\setcounter{secnumdepth}{3}
%\setcounter{tocdepth}{3}


\usepackage[bookmarks, bookmarksopen, bookmarksnumbered]{hyperref}
\usepackage[all]{hypcap}
\urlstyle{rm}

\definecolor{orange}{rgb}{1.0,0.3,0.0}
\definecolor{violet}{rgb}{0.75,0,1}
\definecolor{darkgreen}{rgb}{0,0.6,0}
\definecolor{cyan}{rgb}{0.2,0.7,0.7}
\definecolor{blueish}{rgb}{0.2,0.2,0.8}

\newcommand{\todo}[1]{{\color{blue}$\blacksquare$~\textsf{[TODO: #1]}}}
\newcommand{\katznote}[1]{ {\textcolor{magenta}    { ***Dan:      #1 }}}
\newcommand{\gabnote}[1]{ {\textcolor{cyan}    { ***Gabrielle:     #1 }}}
\newcommand{\nchnote}[1]{  {\textcolor{orange}      { ***Neil: #1 }}}
\newcommand{\manishnote}[1]{  {\textcolor{violet}     { ***Manish: #1 }}}
\newcommand{\davidnote}[1]{  {\textcolor{darkgreen}      { ***David: #1 }}}
\newcommand{\note}[1]{ {\textcolor{red}    { #1 }}}
 
% Don't use tt font for urls
\urlstyle{rm}

% 15 characters / 2.5 cm => 100 characters / line
% Using 11 pt => 94 characters / line
\setlength{\paperwidth}{216 mm}
% 6 lines / 2.5 cm => 55 lines / page
% Using 11pt => 48 lines / pages
\setlength{\paperheight}{279 mm}
\usepackage[top=2.5cm, bottom=2.5cm, left=2.5cm, right=2.5cm]{geometry}
% You can use a baselinestretch of down to 0.9
\renewcommand{\baselinestretch}{0.96}

\sloppypar

\begin{document}

\title[]{Overview and Summary of the First Workshop on Sustainable Software for Science: Practice and Experiences (WSSSPE1)}

\author{Authors TBD}

%\author{Daniel S. Katz$^{(1)}$, Gabrielle Allen$^{(2)}$, Neil Chue Hong$^{(3)}$, \\
%Manish Parashar$^{(4)}$, and David Proctor$^{(1)}$ }
%
%
%\thanks{{}$^{(1)}$ National Science Foundation, Arlington, VA, USA}
%
%\thanks{{}$^{(2)}$ Skolkovo Institute of Science and Technology, Moscow, Russian Federation}
%
%\thanks{{}$^{(3)}$ Software Sustainability Institute, University of Edinburgh, Edinburgh, UK}
%
%\thanks{{}$^{(4)}$ Rutgers Discovery Informatics Institute, Rutgers University, New Brunswick, NJ, USA}


\begin{abstract}
This technical report discusses the First Workshop on Sustainable Software for Science: Practice and Experiences (WSSSPE1). ...
\end{abstract}


\maketitle

\note{papers and presentations and URLs should be references - see
  figshare-web in .bib file for URL style example}

People who have volunteered to work on this report: (with * for actual
contributors - \note{if you contribute, add a * by your name})

The workshop organizers:
\begin{itemize}
\item * Daniel S. Katz $\langle$\url{dkatz@nsf.gov}$\rangle$
\item Gabrielle Allen $\langle$\url{gdallen@illinois.edu}$\rangle$
\item Neil Chue Hong $\langle$\url{N.ChueHong@software.ac.uk}$\rangle$
\item Manish Parashar $\langle$\url{parashar@rutgers.edu}$\rangle$
\item David Proctor $\langle$\url{dproctor@nsf.gov}$\rangle$
\end{itemize}


Additional volunteers:
\begin{itemize}
\item Chris Mattmann $\langle$\url{chris.a.mattmann@jpl.nasa.gov}$\rangle$
\item * Ketan Maheshwari $\langle$\url{ketancmaheshwari@gmail.com}$\rangle$
\item Marlon Pierce $\langle$\url{marpierc@iu.edu}$\rangle$
\item Colin Venters $\langle$\url{C.Venters@hud.ac.uk}$\rangle$
\item Suresh Marru $\langle$\url{smarru@iu.edu}$\rangle$
\item Lynn Zentner $\langle$\url{lzentner@purdue.edu}$\rangle$
\item Anne Elster $\langle$\url{anne.elster@gmail.com}$\rangle$
\item * Shel Swenson $\langle$\url{mdswenso@usc.edu}$\rangle$
\item Andy Ray Terrel $\langle$\url{andy.terrel@gmail.com}$\rangle$
\item Abani Patra $\langle$\url{abani.patra@gmail.com}$\rangle$
\item * Nancy Wilkins-Diehr $\langle$\url{wilkinsn@sdsc.edu}$\rangle$
\item James Spencer $\langle$\url{j.spencer@imperial.ac.uk}$\rangle$
\item * Frank L\"{o}ffler $\langle$\url{knarf@cct.lsu.edu}$\rangle$
\item * James Hetherington $\langle$\url{j.hetherington@ucl.ac.uk}$\rangle$
\item * Sou-Cheng (Terrya) Choi $\langle$\url{sou.cheng.terrya.choi@gmail.com}$\rangle$
\item * James Howison $\langle$\url{james@howison.name}$\rangle$
\item * Bruce Berriman $\langle$\url{gbb@ipac.caltech.edu}$\rangle$
\item Hilmar Lapp $\langle$\url{hlapp@nescent.org}$\rangle$
\item * Marcus D. Hanwell $\langle$\url{marcus.hanwell@kitware.com}$\rangle$
\item Lucas Nussbaum $\langle$\url{lucas.nussbaum@loria.fr}$\rangle$
\item Matthew Turk $\langle$\url{matthewturk@gmail.com}$\rangle$
\end{itemize}

The original document is
\url{https://docs.google.com/document/d/1eVfioGNlihXG_1Y8BgdCI6tXZKrybZgz5XuQHjT1oKU/edit?pli=1#}
(but can no longer be edited).  Note that the original document has
comments in addition to text.


\pagebreak

\section*{Executive Summary}

\todo{1 page summary goes here}

\pagebreak

\section{Introduction}

The First Workshop on Sustainable Software for Science: Practice and
Experiences (WSSSPE1,
\url{http://wssspe.researchcomputing.org.uk/WSSSPE1}) was held on
Sunday, 17 November 2013, in conjunction with the 2013 International
Conference for High Performance Computing, Networking, Storage and
Analysis (SC13, \url{http://sc13.supercomputing.org}).

Because progress in scientific research is dependent on the quality and
accessibility of software at all levels, it is now critical to address many
challenges related to the development, deployment, and maintenance of reusable
software.
%\note{Ketan: What are the levels in scientific process where software
%is required. It might be interesting to outline these stages and types of
%software required in each stage.}
In addition, it is essential that scientists,
researchers, and students are able to learn and adopt software-related skills
and methodologies. Established researchers are already acquiring some of these
skills, and in particular a specialized class of software developers is
emerging in academic environments who are an integral and embedded part of
successful research teams. The WSSSPE workshop was intended to provide a forum
for discussion of the challenges, including both positions and experiences. The
short papers and debates have been archived to provide a basis for continued
discussion, and the workshop has fed into the collaborative writing of this
journal publication. An estimate of 90 to 150 participants were present 
throughout the day. Additional papers based on extended versions of workshop
submissions are expected. The level of interest in the workshop has led the
organizers, working with some of the submitters and attendees, to plan two
additional workshops (at the 2014 SciPy and SC14 conferences) and to turn the
workshop website into a community website that can be used as a focus for
further discussion and progress. Additionally, a minisymposium that aims to
further explore some of the key issues raised in WSSSPE is co-organized by a
WSSSPE1 participant at the 2014 SIAM Annual Meeting on ``Reliable
Computational Science.''

Before the WSSSPE1 workshop took place, the organizers self-published
a paper~\cite{WSSSPE1-pre-report} to document the process of
organizing and advertising the workshop, collecting and reviewing the
papers, and putting together the agenda. Section~\ref{sec:process} is
based on that publication. The remainder of this paper is based on the
workshop itself, as documented in a set of collaborative notes taken
during the workshop~\cite{WSSSPE1-google-notes}, including discussion
about the keynote presentations (\S\ref{sec:keynotes}), the three
panels (\S\ref{sec:devel}-\ref{sec:community}), other discussion
(\S\ref{sec:other}), cross-cutting issues (\S\ref{sec:cross-cutting}),
use cases (\S\ref{sec:use-cases}), and conclusions
(\S\ref{sec:conclusions}).
 
\section{Workshop Process and Agenda} \label{sec:process}

WSSSPE1 was organized in collaboration of the relatively small group
of five organizers and a larger peer-review committee with 36
members. This committee had early influence on the organization, e.g.,
on the specific call for papers.

The workshop call for papers included:

\begin{quote}
In practice, scientific software activities are part of an ecosystem
where key roles are held by developers, users, and funders. All three
groups supply resources to the ecosystem, as well as requirements that
bound it. Roughly following the example of NSF's Vision and Strategy
for Software~\cite{NSF_software_vision},
the ecosystem may be viewed as having challenges related to:

\begin{itemize}[leftmargin=0.2in]
\item the development process that leads to new (versions of) software
\begin{itemize}[leftmargin=0.2in]
\item how fundamental research in computer science or
  science/engineering domains is turned into reusable software
\item software created as a by-product of research
\item impact of computer science research on the development of
    scientific software and vice versa
\end{itemize}
\item the support and maintenance of existing software, including
  software engineering
\begin{itemize}[leftmargin=0.2in]
\item governance, business, and sustainability models
\item the role of community software repositories, their operation and
  sustainability
\end{itemize}
\item the role of open source communities or industry
\item use of the software
\begin{itemize}[leftmargin=0.2in]
\item growing communities
\item reproducibility, transparency needs that may be unique to science
\end{itemize}
\item policy issues, such as
\begin{itemize}[leftmargin=0.2in]
\item measuring usage and impact
\item software credit, attribution, incentive, and reward
\item career paths for developers and institutional roles
\item issues related to multiple organizations and multiple countries,
  such as intellectual property, licensing, etc.
\item mechanisms and venues for publishing software, and the role of
  publishers
\end{itemize}
\item education and training
\end{itemize}

\end{quote}

Based on the goal of encouraging a wide range of submissions from
those involved in software practice, ranging from initial thoughts and
partial studies to mature deployments, the organizers wanted to make
submission as easy as possible. The call for papers stated:

\begin{quote}
We invite short (4-page) position/experience reports that will be used
to organize panel and discussion sessions. These papers will be
archived by a third-party service, and provided DOIs. We encourage
submitters to license their papers under a Creative Commons license
that encourages sharing and remixing, as we will combine ideas (with
attribution) into the outcomes of the workshop.  An interactive site
will be created to link these papers and the workshop discussion, with
options for later comments and contributions. Contributions will be
peer-reviewed for relevance and originality before the links are added
to the workshop site; contributions will also be used to determine
discussion topics and panelists. We will also plan one or more papers
to be collaboratively developed by the contributors, based on the
panels and discussions.
\end{quote}

58 submissions were received, and almost all submitters used either
arXiv~\cite{arXiv-web} or figshare~\cite{figshare-web} to self-publish
their papers.

A peer review process followed the submissions, where
the 58 papers received 181 reviews, an average of 3.12 reviews per
paper. Reviews were completed using a Google form, which allowed
reviewers to choose papers they wanted to review, then to provide
general comments and scores on relevance to the organizers and
to the authors. The review reports enabled the organizers to decide
which papers to associate with the workshop, and allowed the authors
to improve their papers.

The organizers decided to list 54 of the papers as significant
contributions to the workshop, a very high acceptance rate, but one
that is reasonable, given the goal of broad participation and the fact
that the reports were already self-published. The papers were
grouped into three main categories, namely \emph{Developing and
Supporting Software}, \emph{Policy}, and \emph{Communities}. Each
subject area was associated with a panel and discussion at the
workshop.

The workshop itself consisted of two keynote presentations and the
three panels/discussion sessions. The panels were organized based on a
classification of the workshop submissions into three categories,
following the themes of the call for papers as modified by the areas
of the submissions. Three to four representatives from each submission
category were appointed as panelists, and assigned to read a subset of
the paper in that category and then discuss them in the panel.


\section{Keynotes \note{lead: Sou-Cheng (Terrya) Choi} } \label{sec:keynotes}


The WSSSPE1 workshop began with two keynote presentations.


\subsection{A Recipe for Sustainable Software, Philip E. Bourne.} \label{sec:keynote1}

The first keynote~\cite{WSSSPE1-keynote1} was delivered by Philip
E. Bourne of University of California, San Diego.  Bourne is a basic
biomedical scientist but has also formed four software companies. He co-founded 
PLOS Computational Biology~\cite{plos-web} and helped develop the RCSB
Protein Data Bank~\cite{pdb-web}.  
He is working on automating three-dimensional visualizations of cell
contents and molecular structures, a problem that has not been solved
and when done, would serve as a key function of software in biomedical
sciences.

Bourne's keynote presentation was entitled ``A Recipe for Sustainable
Software,'' and developed based on his experiences.  He emphasized that
sustainability for software ``does not just mean more money from
Government'' (see also Section~\ref{sec:cross-cutting}).  Other
factors to consider, he mentioned, include costs of production, ease
of maintenance, community involvement, and distribution channels.

In places, Bourne said, development in science has improved thanks to
open source and hosting services like GitHub~\cite{github-web}, but for the most part
remains arcane. He argued that we can learn much from the App Store
model about interfaces, ratings, and so on. He also mentioned
BioJava~\cite{biojava-web} and Open Science Data Cloud~\cite{osdc-web}
as distribution channels.  On a related note, Bourne observed a common
evolutionary pathway for computational biology projects, from data
archive to analytics platform to educational use, and suggested that
use of scientific software for outreach might be the final step.

Bourne shared with the audience a few real challenges he
encountered. First, also an anecdote, he has looked into
reproducibility in computational biology, but has concluded that ``I
have proved I cannot reproduce research from my own
lab''~\cite{Veretnik}.

Another problem he experienced was staff retention with respect to
private organizations which reward those combining research and
software expertise (the ``Google Bus''). However, he is a strong fan
of software sustainability through public-private partnerships. He
noted that making a successful business from scientific software alone
is very rare: founders overvalue while customers undervalue. He noted
that to last, an open source project needs a minimal funding
requirement even with a vibrant community --- goodwill only goes so
far if one is being paid to do something else.  He talked about grant
schemes of relevance in the U.S., particularly with regard to
technology transfer~\cite{sbir-web, fased-web}.

He also had problems with selling research software: the technology
transfer office in his university wanted huge intellectual property
reach through, whereby they would get a share of profits from drugs
developed by pharmaceutical companies who use the software.  He was
aware this was unrealistic but the technology transfer office insisted
for a while. He wants to push a one-click approach for customers to
purchase university-written software.

He then presented arguments on directly valuing software as
a research output alongside papers, a common discussion within this field.
An interesting reference provided by him
is~\cite{peer-review-code}, which explores involving software
engineers in the review process of scientific code.

On the notion of \emph{digital enterprise}, where information
technology (IT) underpins the whole of organizational activities, he
contended that universities are way behind the curve. In
particular, he highlighted the separation of research, teaching, and
administration into silos without a common IT framework as a blocker
to many useful organizational innovations: ``University 2.0 is yet to
happen.'' He spoke of a circumstance where someone had used an
algorithm developed for computational biology in marketing.
The role of an institution is important in this space. He argued that
funders can help train institutions, not just individuals, in this regard.

He concluded with a reference to his paper~\cite{bourne_ten} and
argued that computational scientists ``have a responsibility to
convince their institutions, reviewers, and communities that software is
scholarship, frequently
more valuable than a research article,'' a point with which all authors
strongly agree.

\subsection{Scientific Software and the Open Collaborative Web, Arfon Smith} \label{sec:keynote2}

The second keynote~\cite{WSSSPE1-keynote2} was delivered by Arfon
Smith of GitHub.

Smith's talk started with an example from data reduction in Astronomy,
where he needed to remove interfering effects from the device. He
built a ``bad pixel mask,'' and realized that while it was persistent,
there was no way or practice of sharing this with the
data. Consequently many researchers repeated the same calculations. He
estimated that 13 person-years were wasted in this redundant
calculation.

``Why didn't we do better?''  Smith asked of this practice. He argued
this was because we were taught to focus on immediate research
outcomes and not on continuously improving and building on tools for
research. He then asked, when we do know better, why we do not act any
different. He argued that it was due to incentives and their lack:
only the immediate products of research, not the software, are valued.
He referenced Victoria Stodden's talk at
OKCon~\cite{okcon-stodden-talk} which he said argued these points
well.

C. Titus Brown~\cite{ged-web}, a WSSSPE1 contributor and participant,
argued that with regard to reusable software, ``we should just start
doing it.'' In this regard Smith replied that documentation should be
``treated as a first class entity.''  He noted that the open source
community has excellent cultures of code reuse, for example,
RubyGems~\cite{rubygems-web}, PyPI~\cite{pypi-web}, and
CPAN~\cite{cpan-web}, where there is effectively low-friction
collaboration through the use of repositories. This has not happened
in highly numerical, compiled language scientific software.  An
exception he cited as a good example of scientific projects using
GitHub is the EMCEE Markov Chain Monte Carlo project~\cite{emcee-web}
by Dan Foreman-Mackey and contributors.

He argued that GitHub's \emph{Pull Request} code review mechanism
facilitates such collaboration, by allowing one to code first, and
seek review and merge back into the trunk later.

``Open source is \ldots reproducible by necessity,'' Smith quoted
Fernando Perez~\cite{perez-open-src-reproducible}, explaining that
reproducibility is a prerequisite for remote collaboration.  He
pointed out that GitHub could propel the next stage of web
development, i.e., ``the collaborative web,'' following on from the
social web of Facebook.

In conclusion Smith reiterated the importance of establishing
incentive models for open contributions and tool builders, for
example, meaningful metrics and research grants such as
\cite{NSF_software_vision}. He urged computational scientists to
collaborate and share often their research reports, teaching
materials, code, as well as data by attaching proper licenses.

\section{Developing and Supporting Software \note{lead: Marcus Hanwell, contributors: Suresh Marru}} \label{sec:devel}

\todo{section should include what was presented and what was discussed}

The panel on developing and supporting software examined the challenges
around scientific software development and support, mainly focused on research
groups that also produce code in various forms. There was widespread agreement
that developing and maintaining software is hard, but best practices can help.
Several participants stated that documentation is not just for users, and paying attention
to API documentation, tutorials for building and deploying software, along with
documented development practices can be very helpful in bringing  new developers
into a project efficiently.

There was discussion that backward compatibility is not always desirable, and it
can be very costly. This must be balanced with the aims of a given project, and how
many other projects depend on and use the code when backwards incompatible
changes are to be made. There are many examples in the wider open source
software world of strategies for dealing with this, and again best practices
can go a long way to mitigating issues around backwards compatibility. Many
projects live with sub-optimal code for a while, and may allow backwards
compatibility to be broken at agreed-upon development points, such as a major
release for a software library.

Communities are extremely important in software projects, and both their
building and continued engagement need attention during the project life cycle.
Several of the submitted papers discussed how communities have been built around
projects, and what is needed to enable a project to grow. Among these are public
source code hosting, mailing lists, documentation, wikis, bug trackers, software
downloads, continuous integration, software quality dashboards, and of course,
a general web presence to tie all of these things together. Questions were posed
around users not answering the questions of other users. Several participants
offered counterexamples, such as mailing lists where developers do not participate
as much due to users being more active, or whether the ``core
team'' can end up setting unrealistic expectations by doing too much. Team Geek\todo{add cite}
and Turk's paper on scaling code in the human dimension\todo{add cite}  discuss how development
lists that are welcoming to people actually have many more people contributing.

Recruiting and/or retaining personnel in this area is hard,
with one of the major reasons being no long-term career paths (especially when
compared with industry). How should software development be balanced with
research? It is apparent that things are beginning to improve, such as
incentives for software development in the form of altmetrics, tenure committee
consideration, and NSF ``products'' vs ``publications.'' It was noted it can be very
difficult to measure where people are using small bits of your code.

There were 13 articles about different experiences in this area, but little
about GUI testing, performance, scalability, or agile development practices.
There were several unique perspectives about issues such as managing API
changes, using the same best practices for software as data, and going beyond
simply ``slapping an OSI-approved license on code.''

The question of what ``sustainable'' means in the context of software was
raised (see \S\ref{sec:cross-cutting}.) The resources at \url{http://oss-watch.ac.uk/resources/ssmm} discuss what
to look for when choosing software for procurement, or reuse in further software
development. Regardless of the license and development model that will be used,
the future of the project must be considered. Even if a particular piece of
software satisfies today's requirements, will it continue to do so in the
future? Important questions include whether the supplier will still be around in five
years time, will it still care for its customers needs, will it be responsive to
bug reports and feature requests? Should you tie your investment to a single
supplier using a proprietary product, or ensure the project uses an OSI-approved
license, and can outlive any single entity if the software is still important.

What is the overarching goal of sustainability? Is it reproducible science,
persistence, quality, something else? How should success be measured in this
context? Is there some metric that can be used to determine when you have
achieved sustainable software, or is this an ongoing process with no clear
endpoint. For truly sustainable software there should be no endpoint, as the
software products continue to be used and useful beyond the single institution,
grant, and developer/development team. Sustainability must be addressed
throughout the project life cycle.

What about actual software engineering principles, such as modularity and
extensibility? This is how industry maintains software, and ensures it continues
to be useful. Often, rewriting software is considered to be too costly, but
with a modular design it can be kept up to date. Extensibility is expected to keep
it relevant, if built into the project. One counterpoint raised by Jason Riedy
was that trying to take advantage of the latest and greatest hardware often
makes this painful, hence the lack of papers mentioning ``GPUs and exotic
hardware.''

The question of whether funders, such as the NSF, can mandate software plans in
much the same way as they do data management plans, was raised. Daniel Katz responded that
software is supposed to be described as part of the NSF data management plan,
and that in NSF's definition, data includes software. A comment from Twitter
(@biomickwatson) raised the issue that this requires reviewers and funders who
understand the answers that are given in these plans. Daniel Katz responded
that in programs focused on software or data this can be done effectively, but
agreed that in more general programs this is indeed a problem.

The papers submitted to this panel, and several others, include lots of general
recommendations for processes, practices, tools, etc. One of the papers
suggested that a ``Software Sustainability Institute'' should be vested with
the authority to develop standardized quality processes, a central common
repository, central resources for services and consulting, a think tank of
sorts, and a software orphanage center. The idea of one common repository received
some resistance, with so many compelling alternatives available, e.g. Bitbucket or
GitHub. The point for centralization of communication/point of contact was seen as
reasonable, with the statement that ``vested with authority'' is perhaps too strong,
but ``providing tools if needed'' might be more appropriate.

Some of the questions raised after the panel discussion are:

Rather than teaching developers about domain science, or domain scientists about
software development practices, why don't we teach both communities to
collaborate more effectively? Can this be done without teaching each side a
little of the other to enable communication, with a response that it really is
not two binary communities, but a spectrum with useful roles in the middle.
The question was raised if a developer can be effective without being part of the
domain community, with responses that this really depends on the specific
problem---translators and T-shaped people are important. Why aren't academic
communities taught how to evaluate cross-disciplinary work well?

What is the role for the growing field of team science? There
is overlap between the communities, with support for virtual organizations,
tool development, etc. How can we make time in an already crowded schedule to
introduce these topics to students? Should they be introduced through lab
classes as in ``real sciences''?

Are there significant differences in projects that have been running for 1, 3,
5, or 10+ years? Are there shared experiences for projects of a similar stage
of maturity? It was noted that computing and communication have changed
significantly over the past decade, and many of the experiences are tied to
the history of computing and communication. See the history of GCC, Emacs, or
the Visualization Toolkit for examples. Others felt that computing has changed
less, but communication and the widespread availability of tools has. It was
noted that email lists, websites, chat rooms, version control, virtual and
physical meetings are all over 20 years old.

There was debate that while some of the basics of computing may be fairly
similar tools commonly used for computing have changed quite
significantly. Reference was made to Perl, which was commonly used, giving way
to whole new languages, such as Python, for gluing things together and how this
induces many students into entirely rewriting the scaffolding, leaving the old
to rot and the experiments to become non-reproducible as the tools change.
Jason Riedy stated that he had been guilty of this in the past. There was
discussion of this tendency along with the enormous differences in the speed and
ease of sharing---having to ship tapes around (GCC, Emacs, etc) as opposed to
the immediate sharing of the latest development online, using revision control
systems like CVS, Subversion, Git, Mercurial, Bazaar, etc.

The question was also posed as to whether the distinction between researcher
and developer is sensible, with James Hetherington commenting that in the UK
a more nuanced view of research software engineers
and researcher developers is examined. Should this be less of a contract relationship, and
more of a collaborative relationship? This is also at the core of the business
model that Kitware presented in its submission to the workshop. Are other
ingredients missing such as applied mathematicians? Should this be defined more
in terms of skill sets rather than roles and/or identities? This builds on the
comments from Vaidy Sunderam that scientists are generally good writers, and
have mathematical skills, so why can't they learn software engineering
principles?

Miller commented that all of the infrastructure that sits around a new
algorithm that we need to make it useful and sustainable requires different
skill sets than the algorithm developer. Friere commented that there are no
good career paths for people with broad skills, no incentives for them to
continue in these roles. There was debate around people doing what interests
them, and learning computing leaves people cold, but is it that it leaves the
people who find career paths in academia cold versus the full spectrum of
people involved in research? Is this also caused by poor teaching, or because the
benefits for doing this are perceived as too small? It could also be attributed to
their focus being on science, not software engineering, or do people with
the passion for software engineering in science simply have no viable career
path and either adapt or seek out alternate career paths?

\subsection*{Papers}

\subsubsection*{Development Experiences}

\begin{itemize}

\item Mark C. Miller, Lori Diachin, Satish Balay, Lois Curfman
  McInnes, Barry Smith. Package Management Practices Essential for
  Interoperability: Lessons Learned and Strategies Developed for
  FASTMath \cite{Miller_WSSSPE}

\item Karl W. Broman, Thirteen years of R/qtl: Just barely sustainable
  \cite{Broman_WSSSPE}

\item Charles R. Ferenbaugh, Experiments in Sustainable Software
  Practices for Future Architectures \cite{Ferenbaugh_WSSSPE}

\item Eric G Stephan, Todd O Elsethagen, Kerstin Kleese van Dam, Laura
  Riihimaki. What Comes First, the OWL or the Bean?
  \cite{Stephan_WSSSPE}

\item Derek R. Gaston, John Peterson, Cody J. Permann, David Andrs,
  Andrew E. Slaughter, Jason M. Miller, Continuous Integration for
  Concurrent Computational Framework and Application Development
  \cite{Gaston_WSSSPE}

\item Anshu Dubey, B. Van Straalen. Experiences from Software
  Engineering of Large Scale AMR Multiphysics Code Frameworks
  \cite{Dubey_WSSSPE}

\item Markus Blatt. DUNE as an Example of Sustainable Open Source
  Scientific Software Development \cite{Blatt_WSSSPE}

\item David Koop, Juliana Freiere, Cl\'{a}udio T. Silva, Enabling
  Reproducible Science with VisTrails~\cite{Koop_WSSSPE}

\item Sean Ahern, Eric Brugger, Brad Whitlock, Jeremy S. Meredith,
  Kathleen Biagas, Mark C. Miller, Hank Childs, VisIt: Experiences
  with Sustainable Software \cite{Ahern_WSSSPE}

\item Sou-Cheng (Terrya) Choi. MINRES-QLP Pack and Reliable
  Reproducible Research via Staunch Scientific Software
  \cite{Choi_WSSSPE}

\item Michael Crusoe, C. Titus Brown. Walking the talk: adopting and
  adapting sustainable scientific software development processes in a
  small biology lab \cite{Crusoe_WSSSPE}

\item Dhabaleswar K. Panda, Karen Tomko, Karl Schulz, Amitava Majumdar.
The MVAPICH Project: Evolution and Sustainability of an Open Source
Production Quality MPI Library for HPC \cite{Panda_WSSSPE}

\item Eric M. Heien, Todd L. Miller, Becky Gietzel, Louise
  H. Kellogg. Experiences with Automated Build and Test for
  Geodynamics Simulation Codes \cite{Heien_WSSSPE}

\end{itemize}

\subsubsection*{Deployment, Support, and Maintenance of Existing Software}

\begin{itemize}

\item Henri Casanova, Arnaud Giersch, Arnaud Legrand, Martin Quinson,
  Fr\'{e}d\'{e}ric Suter. SimGrid: a Sustained Effort for the
  Versatile Simulation of Large Scale Distributed
  Systems~\cite{Casanova_WSSSPE}

\item Erik Trainer, Chalalai Chaihirunkarn, James Herbsleb. The Big
  Effects of Short-term Efforts: A Catalyst for Community Engagement
  in Scientific Software \cite{Trainer_WSSSPE}

\item Jeremy Cohen, Chris Cantwell, Neil Chue Hong, David Moxey,
  Malcolm Illingworth, Andrew Turner, John Darlington, Spencer
  Sherwin. Simplifying the Development, Use and Sustainability of HPC
  Software \cite{Cohen_WSSSPE}

\item Jaroslaw Slawinski, Vaidy Sunderam. Towards Semi-Automatic
  Deployment of Scientific and Engineering Applications
  \cite{Slawinski_WSSSPE}

\end{itemize}

\subsubsection*{Best Practices, Challenges, and Recommendations}

\begin{itemize}

\item Andreas Prli\'{c}, James B. Procter. Ten Simple Rules for the
  Open Development of Scientific Software \cite{Prlic_WSSSPE}

\item Anshu Dubey, S. Brandt, R. Brower, M. Giles, P. Hovland,
  D. Q. Lamb, F. Löffler, B. Norris, B. O'Shea, C. Rebbi, M. Snir,
  R. Thakur, Software Abstractions and Methodologies for HPC
  Simulation Codes on Future Architectures \cite{Dubey2_WSSSPE}

\item Jeffrey Carver, George K. Thiruvathukal. Software Engineering
  Need Not Be Difficult \cite{Carver_WSSSPE}

\item Craig A. Stewart, Julie Wernert, Eric A. Wernert, William
  K. Barnett, Von Welch. Initial Findings from a Study of Best
  Practices and Models for Cyberinfrastructure Software Sustainability
  \cite{Stewart_WSSSPE}

\item Jed Brown, Matthew Knepley, Barry Smith. Run-time extensibility:
  anything less is unsustainable \cite{Brown_WSSSPE}

\item Shel Swenson, Yogesh Simmhan, Viktor Prasanna, Manish Parashar,
  Jason Riedy, David Bader, Richard Vuduc. Sustainable Software
  Development for Next-Gen Sequencing (NGS) Bioinformatics on Emerging
  Platforms \cite{Swenson_WSSSPE}

\end{itemize}

\subsection{Research or Reuse?}

Discussion of software produced as a by-product versus software
developed for reuse. How does this change the project, who develops
the code, growth beyond 1--2 person projects to larger projects with
diverse set of consumers and contributors. Modular and extensible code
versus working for current research problem---tackled by same people,
or a collaborative team?

\subsection{Defining Sustainability for Scientific Software}

What is sustainable? What are the best practices, can workshops fund
meetings to help define and improve best practices in these areas?
Software plans from the funding agencies? This topic is expanded upon
in \S\ref{sec:cross-cutting}, since it was discussed up in multiple
parts of the WSSSPE1 workshop.

\subsection{Training Scientists to Develop and Support Software}

Discussion of the evolving role of scientists, and/or others that fill
these roles.

\subsection{Software Process, Code Review, Automation, Reproducibility}

There are a lot of tools out there, but few are currently used. Look
at what some projects have found successful, and how to automate as
much as possible to reduce additional overhead.

\subsection{Software and Data Licensing}

Its impact on how and where research products are used, who can
collaborate and what patterns have worked/not worked in existing
communities.

\subsection{Funding, Sustainability Beyond the First Grant/Institution}

How initial software development is funded, moving to follow up
projects, maintenance, community growth, collaborating with other
institutions, labs, industry, internationally. Contract relationship
versus collaborative development between scientists and software
developers.

\subsection{Training Others to use Software}

Who creates training materials, how are they distributed, integration
into courses when projects see very wide application in research.

\section{Policy \note{lead: Colin Venters, contributors: James Howison, Hilmar Lapp}} \label{sec:policy}

\todo{section should include what was presented and what was discussed}

\note{Question of extent to which this section (indeed the whole document) should call out to existing work on these questions, or stick to summarizing the papers and the discussion. I think we should call out as much as possible --JamesHowison}

\note{Dan: I think this is a report on the workshop, and as we need to refer to other things, that's fine, but the focus should be on what was submitted and discussed.}

\subsection*{Papers}

\subsubsection*{Modeling Sustainability}

\begin{itemize}

\item Coral Calero, M. Angeles Moraga, Manuel F. Bertoa. Towards a
  Software Product Sustainability Model \cite{Calero_WSSSPE}

\item Colin C. Venters, Lydia Lau, Michael K. Griffiths, Violeta
  Holmes, Rupert R. Ward, Jie Xu. The Blind Men and the Elephant:
  Towards a Software Sustainability Architectural Evaluation Framework
  \cite{Venters_WSSSPE}

\item Marlon Pierce, Suresh Marru, Chris Mattmann. Sustainable
  Cyberinfrastructure Software Through Open Governance
  \cite{Pierce_WSSSPE}

\item Daniel S. Katz, David Proctor. A Framework for Discussing
  e-Research Infrastructure Sustainability \cite{Katz_WSSSPE}

\item Christopher Lenhardt, Stanley Ahalt, Brian Blanton, Laura
  Christopherson, Ray Idaszak. Data Management Lifecycle and Software
  Lifecycle Management in the Context of Conducting Science
  \cite{Lenhardt_WSSSPE}

\item Nicholas Weber, Andrea Thomer, Michael Twidale. Niche Modeling:
  Ecological Metaphors for Sustainable Software in Science
  \cite{Weber_WSSSPE}

\end{itemize}

\subsubsection*{Credit, Citation, Impact}

The policy panel and discussion addressed the question of recognition of work on scientific software and linked that recognition to questions of reward and thus motivation for particular kinds of work on scientific software. In short, software work in science was seen to be inadequately visible in ways that ``count'' within the reputation system underlying science. In his paper for this workshop, Katz placed software work along with other ``activities that facilitate science but are not currently rewarded or recognized'' \cite{Katz_WSSSPE}. Priem and Piwowar argued for the need to ``support all researchers in presenting meaningful impact evidence in tenure, promotion, and funding applications.'' \cite{Priem_WSSSPE}.  Kneply et al. argued that the visibility of software that supported a piece of science ``can have detrimental effects on funding, future library development, and even scientific careers.'' \cite{Knepley_WSSSPE}.

These papers, and the discussion at the workshop, join a nascent literature seeking to understand what drives software work in science and how the reward systems of science thereby shape the type of software work undertaken, including the extent to which developers are motivated to build software for the long-term, for the use of others and whether to work collaboratively or separately \cite{howison_incentives_2013, howison_scientific_2011, bietz_synergizing_2010}. Software work is not only motivated by direct citations, but the visibility of software work in the literature is important to those who write software used in science.

Papers and discussion concentrated in three areas: How then ought software work to be visible, what are the barriers to its visibility, and what can be done to make it more visible? 

Most of the papers in this area focused on visibility of software in scientific papers, since scientific papers are the most widely accepted documentation of achievement in science. It was noted that there appear to be no widely accepted standards on how the use of software towards a paper ought to be mentioned, that journals, citation style guides and other guides to scientific conduct are vague about how to describe software. To address this, papers spoke of a need for a fixed identifier for software, either directly through a mechanism such as a Digital Object Identifier \cite{Katz_WSSSPE,Knepley_WSSSPE} or via a published paper written to document the software (and perhaps its creation), a ``software paper'' \cite{Chue_Hong_WSSSPE}.

Another approach is to try to reduce the difficulty of citing software for authors, acknowledging that authors are often working with software that itself wraps other software and therefore hides that software. Knepley et al approach this by proposing a mechanism by which the software itself, after it has run, provides the user with a set of citations that are relevant to the code actually run. They describe a prototype implementation whereby the citations are embedded in libraries and reported along with the results, via a commandline interface \cite{Knepley_WSSSPE}. Discussion highlighted the difficulty that attempting to acknowledge the contributions of all pieces of dependent code within a paper faces the difficulty of creating very long citation lists, straining the analogy of code used to papers cited. Katz approaches this issue by proposing a system of ``transitive credit,'' recording dependencies and relative contributions outside particular papers, relieving authors from the responsibility of acknowledging each and every dependency. In stead authors would acknowledge the percentage contribution of the software they used directly and an external system would then be able to recursively allocate that credit to those who had provided dependencies. Finally Priem and Piwowar argued that machine learning techniques could examine the body of published literature and extract mentions of software, coping with the multitude of informal ways in which authors mention software they have used \cite{Priem_WSSSPE}.  Discussion included turning the emphasis from asking users to improve their citation of software contributions, to ask how projects producing software might monitor the literature to improve their ability to show impact. Michael McLennan described the approach taken by the NanoHub project to scan the literature using keywords and names of known users to discover papers that are likely to have used their software and platform, then to have graduate students read each paper, highlighting any mention and perhaps following up with the authors to locate stories of impact.  Work since the workshop has described this process at publications.wikia.com.

Acknowledgement in science does not come only in publications, of course. A key location for visibility might be in the grant funding process, both in bio-sketches and in grant project reporting. Some progress has been made here. Representatives of the NSF at the meeting emphasized these opportunities and encouraged participants to take advantage of them. Nonetheless there was skepticism that peer review panels would value these contributions in the same was as publications). 

Priem and Piwowar argued for additionally looking beyond publications and drawing on evidence of contribution, and impact, recorded in other online systems, such as source code repositories like github, both code contributions, downloads of code and dependencies as well as conversations about software (mailing lists, twitter and beyond) \cite{Priem_WSSSPE}. They argue for providing scholars with flexible resources so that they can tell their own stories in the manner most appropriate for them and their audiences, a principle of the ``alt.metrics'' approach.

\todo{convert this sketch to discussion of policy options}	
	Opportunities for Policy interventions:
		Funding agencies
		Journals.  Success of data policies, growth of software policies.
		Promotion and Tenure. Follow lead of Science of Team Science in surveying policies at universities and other institutes.

\todo{review PiratePad notes for other aspects of credit-giving discussed.}
\begin{itemize}

\item Matthew Knepley, Jed Brown, Lois Curfman McInnes, Barry
  Smith. Accurately Citing Software and Algorithms Used in
  Publications \cite{Knepley_WSSSPE}

\item Jason Priem, Heather Piwowar. Toward a comprehensive impact
  report for every software project \cite{Priem_WSSSPE}

\item Daniel S. Katz. Citation and Attribution of Digital Products:
  Social and Technological Concerns \cite{Katz2_WSSSPE}

\item Neil Chue Hong, Brian Hole, Samuel Moore. Software Papers:
  improving the reusability and sustainability of scientific software
  \cite{Chue_Hong_WSSSPE}

\end{itemize}

In addition, the following paper from another area were also discussed
in this area.

\begin{itemize}

\item Frank L\"{o}ffler, Steven R. Brandt, Gabrielle Allen and Erik
  Schnetter. Cactus: Issues for Sustainable Simulation Software
  \cite{Loffler_WSSSPE}

\end{itemize}

\subsubsection*{Reproducibility}

\begin{itemize}

\item Victoria Stodden, Sheila Miguez. Best Practices for
  Computational Science: Software Infrastructure and Environments for
  Reproducible and Extensible Research \cite{Stodden_WSSSPE}

\end{itemize}

\subsubsection*{Implementing Policy}

\begin{itemize}

\item Randy Heiland, Betsy Thomas, Von Welch, Craig Jackson. Toward a
  Research Software Security Maturity Model \cite{Heiland_WSSSPE}

\item Brian Blanton, Chris Lenhardt, A User Perspective on Sustainable
  Scientific Software \cite{Blanton_WSSSPE}

\item Daisie Huang, Hilmar Lapp. Software Engineering as
  Instrumentation for the Long Tail of Scientific Software
  \cite{Huang_WSSSPE}

\item Rich Wolski, Chandra Krintz, Hiranya Jayathilaka, Stratos
  Dimopoulos, Alexander Pucher. Developing Systems for API Governance
  \cite{Wolski_WSSSPE}

\end{itemize}


\subsection{Career Tracks for Scientific Software Developers}

How to ensure software is sustainable by ensuring there are career
paths for developers.

What are the possible career paths for a specialist software developer working as part of a scientific research group?

\section{Communities \note{lead: Matthew Turk, contributors: Nancy Wilkins-Diehr, Chris Mattmann, Suresh Marru, Frank L\"{o}ffler, Andy Terrel}} \label{sec:community}


\todo{section should include what was presented and what was discussed}

There were a number of papers categorized under the Communities banner and so
two presenters each summarized half of the submissions in this area.

\subsection{Communities Part 1}

This collection of papers was summarized by Karen Cranston.

Drawing on experiences from high-energy physics, \cite{Vay_WSSSPE} proposed
developing teams of technical specialists able to overcome a lack of
coordination between projects.  Maximization of scientific output requires
maximizing the usability of the scientific codes while minimizing the cost of
developing and supporting those codes.  This included targeting different
architectures for their software to be deployed, as well as coordination
between technically-focused individuals and usage of a common scripting
language between projects.  Instead of fragmenting the development of
simulation codes across institutions, the paper suggests that a cohesive
strategy reducing duplication and increasing coordination will broadly increase
the efficiency across institutions.  The approach proposed is of de-fragmenting
the existing ecosystem in a non-disruptive way.

The paper by Maheshwari et al.~\cite{Maheshwari_WSSSPE} focuses on ``technology
catalysts" and their role in the modern scientific research process. Technology
catalyst could be defined as a role played by an individual with a know-how of
technological advancements, tasked with user engagement with a goal of enacting
scientific or engineering applications, and using suitable tools and techniques
to take advantage of technological capabilities and benefiting applications.

One of the tasks of catalysts is to seek community collaborations for new
applications and user engagement thus benefiting both: science, by effective
running of scientific codes on computational infrastructure, and technology,
by conducting research and seeking findings for technology improvement.
The particular engagements described in the paper came up from authors work as
postdoctoral researcher at Cornell and Argonne. Interaction with the scientific
communities in both institutions resulted in these collaborations.

In \cite{Hanwell_WSSSPE}, the authors reflect on the 15-year history of open
source software development at Kitware.  In particular, they focus on their
success at growing their community of users through enabling multiple channels
of communication, directly reaching out to individuals, and lowering the
barrier to entry for contributions.  This involves providing clear,
test-oriented and review-based mechanisms for evaluating contributions,
permissive licenses, and a service-based model for sustaining development.
This model enables Kitware to review both public funding, as well as private
funding to support improvements and targeted developments of the software.

At NESCent, a combination of in-house informatics individuals and domain
scientists collaborate to develop software to study evolutionary science.  The
report, \cite{Cranston_WSSSPE}, studied the success of a ``hackathon'' model
for development, where short-form, hands-on events combining users,
researcher-developers and software engineers targeted specific code
improvements.  From this experiment, the authors identified sweveral key
outcomes as well as lessons-learned -- specifically, the co-localization of
developers was seen as having a strong impact, enabling casual conversation
that led to discrete outcomes.  The formation of the discussion mailing list,
specifically in response to the social capital built at the hackathon, was seen
as spurring on longer-term benefits to the community and fostering
sustainability.

\cite{Hart_WSSSPE} addresses the success of the rOpenSci project in developing
collaborations supporting tool development for Open Science.  This software
collective, organized around the statistical programming environment R,
develops access mechanisms for data repositories and attempts to reduce the
barrier to entry for individuals wanting to access data repositories and study
the data contained therein.  The collective fosters direct collaboration
between individuals and data providers, designed to ``train academics in
reproducible science workflows focused around R.''  The two central challenges
to this goal were identified as engagement of existing users within ecology and
evolutionary biology (EEB), and how can the community make inroads and traction
in other disciplines?  Currently, the collective is exploring addressing these
challenges through use of social media and holding workshops and hackathons.
This helps to both raise the profile of the collective within EEB and in other
domains.  However, the overarching challenge identified in the paper was that
of incentivizing maintenance of software, which is difficult in academia.

\subsection{Communities Part 2}

Nancy Wilkins-Diehr summarized 6 papers in this part.

The Christopherson paper outlines the degree to which research relies on high
quality software. There are often barriers and a lack of suitable incentives
for researchers to embrace software engineering principals. The Water Science
Software Institute is working to lower some of these barriers through an Open
Community Engagement Process. This is a 4-step iterative development process
that incorporates Agile development principals.

\begin{itemize}
\item Step 1: Design - thorough discussion of research questions
\item Step 2: Develop working code
\item Step 3: Refine based on new requirements
\item Step 4: Publish open source
\end{itemize}

The Christopherson paper reports on the application of Steps 1-3 to a
computational modeling framework developed in the 1990s. Step 1 was realized as
a 2-day, in person specifications meeting and code walkthrough. Step 2 was a
5-day hackathon to develop working code, and Step 3 a 3-day hackathon to refine
the code based on new requirements. The team worked on small, low-risk units of
code. It was challenging, revealed unanticipated obstacles, programmers had to
work together, and experimentation was encouraged.

The paper summarized recommendations to others wishing to engage in this or a
similar process, starting small and gradually building toward more complex
objectives. This is consistent with Agile development. Refactor before adding
new functionality. Approach development as a learning experience. Welcome
experimentation, and treat mistakes as a natural part of the learning process.
Repeat Step 1 activities before all hackathons to develop consensus before
coding. This allows coding to be the focus of subsequent hackathons. In higher
risk situations, provide additional time for Step 1 activities. The
Christopherson team recommends a minimum of two months. Ensure any newcomers
receive some form of orientation prior to the hackathon, such as a code
walkthrough or system documentation. Co-locate rather than collaborating
remotely whenever feasible.

The Pierce paper described how science gateways can provide a user-friendly
entry to complex cyberinfrastructure. The paper opens with a description of the
explosion of use of just a few gateways. Over 3.5 years, more than 7,000
biologists have run phylogenetic codes on supercomputers using the CIPRES
Science Gateway. In 1 year, over 120 scientists from 50 institutions used the
UltraScan Science Gateway, increasing the sophistication of analytical
ultracentrifugation experiments worldwide. The new Neuroscience Gateway (NSG)
registered 100+ users who used 250,000 CPU hours in only a few months.

Gateways, however, need to keep operational costs low and can often make use of
common components. Science Gateway Platform as a Service (Sci-GaP) delivers
middleware as a hosted, scalable third-party service while domain developers
focus on user interfaces and domain-specific data in the gateway. The
middleware handles things like authentication, application installation and
reliable execution and help desk support.

One key to SciGaP is its openness. While based on the Apache Airavata project
and the CIPRES Workbench Framework, community contributions are encouraged
because of its open source, open governance and open operations policies. The
goal is robust, sustainable infrastructure with a cycle of development that
improves reliability and prioritizes stakeholder requirements. The project is
leveraging Internet2's Net+ mechanisms for converting SciGaP and its gateways
into commodity services.

The Zentner paper describes experiences and challenges with the large
nanoHUB.org community. The authors define community as a ``body of persons of
common and especially professional interests scattered through a larger
society.'' This makes support challenging because of the diversity of
viewpoints and needs. The group constantly examines its policies to determine
whether they are indirectly alienating part of the community or encouraging
particular types of use.

nanoHUB's 10-year history with over 260,000 users annually provides a lot of
data to analyze. 4000 resources contributed by 1000 authors. nanoHUB serves
both the research and education community and the contribution model allows
researchers to get their codes out into the community and in use in education
very rapidly. The primary software challenges are twofold - support for the
HUBzero framework and challenges related to the software contributed by the
community.

The group has learned that community contributions are maximized with a
tolerant licensing approach. HUBzero uses an LGPLv3 license so contributors can
create unique components and license as they choose. If they make changes to
source code, the original license must be maintained for redistribution. As far
as contributed resources, these must be open access, but not necessarily open
source. This allows contributors to meet the requirements of their institutions
and funding agencies. Quality is maintained via user ratings. Documentation is
encouraged and nanoHUB supplies regression test capabilities, but the user
community provides ratings, poses questions and contributes to wishlists and
citation counts - all of which incentivize code authors.

The Terrel paper describes support for the Python scientific community through
two major efforts - the SciPy conference and the NumFOCUS foundation. Reliance
on software in science has driven a huge demand for development, but this
development is typically done as a side effort and often in a rush to publish
without documentation and testing. While created by academics, software support
often falls to industrial institutions. SciPy brings together industry,
government, and academics to share their code and experience in an open
environment.

NumFOCUS promotes open, usable scientific software while sustaining the
community. Specific activities include educational programs, collaborative
research tools and documentation and promotion of high-level languages,
reproducible scientific research, and open-code development. Governance of the
non-profit is a loose grantor-grantee relationship with projects allowing for
monies to be placed in the groups accounts. This has raised money to hire
developers for open code development, maintain testing machines, organize the
PyData conference series, and sponsor community members to attend conferences.

Software sustainability relies on contributions from all sectors of the user
community. Together SciPy and NumFOCUS support these sectors. By maximizing
contributions growing the user base they help develop and mature Python.

The L\"{o}ffler paper describes the Cactus project which was started in 1996 by
participants in USA Binary Black Hole Alliance Challenge. Cactus has a flesh
and thorns, core and module, model - a community-oriented framework that allows
researchers to easily work together with reusable and extendable software
elements. Modules are compiled into an executable and can remain dormant,
becoming active only when parameters and simulation data dictate. Users can
use modules written by others or can write their own modules without changing
other code. The community has grown and diversified beyond the original science
areas.

The paper points out 4 keys to sustaining the community - modular design,
growing a collaborative community, career paths and credit. In modular design,
the Cactus project went far beyond standard practices of APIs. Domain specific
languages (DSLs) allow decoupling of components - for example I/O, mesh
refinement, PAPI counters, and boundary conditions abstracted from science
code. In academia, publications are the main currency of credit. Because the
project connects code developments to science, the work is publishable and
modules are citable. Because of the open source, modular approach, programmers
can see the impact of their contributions and often continue work after
graduation. Career paths remain a challenge, however. Tasks that are essential
from a software engineering perspective are often not rewarded in academia. The
best programmers in a science environment often have multidisciplinary
expertise. That also is not rewarded in academia.

The Wilkins-Diehr paper describes an NSF software institute effort to build a
community of those creating science gateways or web portals for science. These
gateways, as described in some of the other papers in this section, can be
quite capable, having a remarkable impact on some parts of science.

This paper mentioned challenges highlighted by other papers in this section -
mainly the conflict between funding for research vs infrastructure and the
challenges around getting academic credit for infrastructure. Because the
authors have studied many projects, they've also observed how development is
often done in an isolated hobbyist environment. Developers are unable to take
advantage of similar work done by others, isolation even when projects have
common needs. But often projects struggle for sustainable funding because they
provide infrastructure to conduct research and many times only the research is
funded. Gateways also may start as small group research project, taking off in
popularity once they go live without any long term plans for sustainability or
without resources in the project to plan for such. Subsequent disruptions in
service can limit effectiveness and test the limits of the research community's
trust. The impact of gateways can be increased substantially if we understand
what makes them successful.

Recommendations from an early study of successful gateways include the
following. Leadership and management teams should design governance to
represent multiple strengths and perspectives, plan for change and turnover in
the future, recruit a development team that understands both the technical and
domain-related issues, consider sustainability and measure success early and
often. Successful projects recognize the benefits and costs of hiring a team of
professionals, demonstrate credibility through stability and clarity of
purpose, leverage the work of others and plan for flexibility. Successful
projects identify an existing community and understand the communities' needs
before beginning. Projects adapt as the communities' needs evolve. For funders,
the lifecycle of technology projects must be considered. Solicitations should
be designed to reward effective planning, recognize the benefits and
limitations of both technology innovation and reuse, expect adjustments during
the production process, copy effective models from other industries and
sectors, and encourage partnerships that support gateway sustainability.

Through a business incubator type approach, the institute plans to provide a
variety of services that could be shared amongst projects. Consultation and
resources on topics such as business plan development, software engineering
practices, software licensing options, usability, security and project
management as well as a software repository and hosting service will be
available. Experts will be available for multi-month assignments to help
research teams build their own gateways, teaching them how to maintain and add
to the work after the collaboration ends. Forums, symposia and an annual
conference will connect members of the development community. A modular,
layered framework that supports community contributions and allows developers
to choose components will be delivered and finally workforce development
activities will help train the next generation for careers in this cross-
disciplinary area and build pools of institutional expertise that many projects
can leverage. Shared services and forums can dramatically reduce the cost of
building and sustaining gateways. Workforce development can encourage
technology professionals to remain in the sciences.


\subsection*{Papers}

\subsubsection*{Communities Part 1 Papers}

\begin{itemize}

\item Reagan Moore. Extensible Generic Data Management Software
  \cite{Moore_WSSSPE}

\item Karen Cranston, Todd Vision, Brian O'Meara, Hilmar Lapp. A
  grassroots approach to software sustainability
  \cite{Cranston_WSSSPE}

\item J.-L. Vay, C. G. R. Geddes, A. Koniges, A. Friedman,
  D. P. Grote, D. L. Bruhwiler. White Paper on DOE-HEP Accelerator
  Modeling Science Activities \cite{Vay_WSSSPE}

\item Ketan Maheshwari, David Kelly, Scott J. Krieder, Justin M. Wozniak, Daniel S. Katz, Mei Zhi-Gang, Mainak Mookherjee. Reusability in Science: From Initial User Engagement to Dissemination of Results \cite{Maheshwari_WSSSPE}

\item Edmund Hart, Carl Boettiger, Karthik Ram, Scott Chamberlain. rOpenSci -- a collaborative effort to develop R-based tools for facilitating Open Science \cite{Hart_WSSSPE}

\end{itemize}

\subsubsection*{Communities Part 2 Papers}

\begin{itemize}

\item L. Christopherson, R. Idaszak, S. Ahalt. Developing Scientific Software through the Open Community Engagement Process \cite{Christopherson_WSSSPE}

\item Marlon Pierce, Suresh Marru, Mark A. Miller, Amit Majumdar, Borries Demeler. Science Gateway Operational Sustainability: Adopting a Platform-as-a-Service Approach \cite{Pierce2_WSSSPE}

\item Lynn Zentner, Michael Zentner, Victoria Farnsworth, Michael
  McLennan, Krishna Madhavan, and Gerhard Klimeck, nanoHUB.org:
  Experiences and Challenges in Software Sustainability for a Large
  Scientific Community \cite{Zentner_WSSSPE}

\item Andy Terrel. Sustaining the Python Scientific Software Community
  \cite{Terrel_WSSSPE}

\item Frank L\"{o}ffler, Steven R. Brandt, Gabrielle Allen and Erik
  Schnetter. Cactus: Issues for Sustainable Simulation Software
  \cite{Loffler_WSSSPE}

\item Nancy Wilkins-Diehr, Katherine Lawrence, Linda Hayden, Marlon Pierce, Suresh Marru, Michael McLennan, Michael Zentner, Rion Dooley, Dan Stanzione. Science Gateways and the Importance of Sustainability \cite{Wilkins-Diehr_WSSSPE}

\end{itemize}

In addition, the following paper from another area was also discussed
in this area.

\begin{itemize}

\item Marcus Hanwell, Amitha Perera, Wes Turner, Patrick O'Leary,
  Katie Osterdahl, Bill Hoffman, Will Schroeder. Sustainable Software
  Ecosystems for Open Science \cite{Hanwell_WSSSPE}

\end{itemize}

\subsubsection*{Industry \& Economic Models}

\begin{itemize}

\item Anne C. Elster. Software for Science: Some Personal Reflections
  \cite{Elster_WSSSPE}

\item Ian Foster, Vas Vasiliadis, Steven Tuecke. Software as a Service
  as a path to software sustainability \cite{Foster_WSSSPE}

\item Marcus Hanwell, Amitha Perera, Wes Turner, Patrick O'Leary,
  Katie Osterdahl, Bill Hoffman, Will Schroeder. Sustainable Software
  Ecosystems for Open Science \cite{Hanwell_WSSSPE}

\end{itemize}

In addition, the following papers from other areas were also discussed
in this area.

\begin{itemize}

\item Brian Blanton, Chris Lenhardt, A User Perspective on Sustainable
  Scientific Software \cite{Blanton_WSSSPE}

\item Markus Blatt. DUNE as an Example of Sustainable Open Source
  Scientific Software Development \cite{Blatt_WSSSPE}

\item Dhabaleswar K. Panda, Karen Tomko, Karl Schulz, Amitava
  Majumdar. The MVAPICH Project: Evolution and Sustainability of an
  Open Source Production Quality MPI Library for HPC
  \cite{Panda_WSSSPE}

\item Andy Terrel. Sustaining the Python Scientific Software Community
  \cite{Terrel_WSSSPE}

\end{itemize}

\subsubsection*{Education \& Training}

\begin{itemize}

\item Ivan Girotto, Axel Kohlmeyer, David Grellscheid, Shawn
  T. Brown. Advanced Techniques for Scientific Programming and
  Collaborative Development of Open Source Software Packages at the
  International Centre for Theoretical Physics (ICTP)
  \cite{Girotto_WSSSPE}

\item Thomas Crawford. On the Development of Sustainable Software for
  Computational Chemistry \cite{Crawford_WSSSPE}

\end{itemize}

In addition, the following papers from other areas were also discussed
in this area.

\begin{itemize}

\item Charles R. Ferenbaugh, Experiments in Sustainable Software
  Practices for Future Architectures \cite{Ferenbaugh_WSSSPE}

\item David Koop, Juliana Freiere, Cl\'{a}udio T. Silva, Enabling
  Reproducible Science with VisTrails~\cite{Koop_WSSSPE}

\item Sean Ahern, Eric Brugger, Brad Whitlock, Jeremy S. Meredith,
  Kathleen Biagas, Mark C. Miller, Hank Childs, VisIt: Experiences
  with Sustainable Software \cite{Ahern_WSSSPE}

\item Sou-Cheng (Terrya) Choi. MINRES-QLP Pack and Reliable
  Reproducible Research via Staunch Scientific Software
  \cite{Choi_WSSSPE}

\item Frank L\"{o}ffler, Steven R. Brandt, Gabrielle Allen and Erik
  Schnetter. Cactus: Issues for Sustainable Simulation Software
  \cite{Loffler_WSSSPE}

\item Erik Trainer, Chalalai Chaihirunkarn, James Herbsleb. The Big
  Effects of Short-term Efforts: A Catalyst for Community Engagement
  in Scientific Software \cite{Trainer_WSSSPE}

\end{itemize}

\subsection{What are communities?}
\subsection{Challenges of community}
include metrics for community success (e.g., more external
contributors than internal).
\subsection{Admirable scientific software communities}
\begin{itemize}
\item example communities
\item their (quick) origin stories.
\end{itemize}
\subsection{Resources for learning about software communities}
\begin{itemize}
\item academic fields studying communities (and software communities)
\item courses on online communities
\item books
\item need for software carpentry module on organizing communities?
\end{itemize}

\section{Other Discussion} \label{sec:other}

\note{from the misc questions/answers/observations part of the google doc?}

\note{all to put notes here of stuff that doesn't fit elsewhere, if any}

\todo{perhaps remove this section}


\section{Cross-cutting Issue: Defining Sustainability \note{lead: Daniel S. Katz}}  \label{sec:cross-cutting}

\note{So far this reads a lot like a collection of thoughts only, without ``red line''.}
\note{Dan: assuming the previous note is from FL, what do you propose?}
The question of what was meant by ``sustainability'' in the context of software
came up in many different parts of the workshop, specifically in the first
keynote (\S\ref{sec:keynote1}), the Developing and Maintaining Software panel,
and the Policy panel.

In the opening keynote, Philip Bourne suggested that perhaps sustainability can
be defined as the effort that happens to make the essential things continue.
This leads to having to decide what it is that we want to sustain, whether what
we want to sustain is valuable, and finally, who would care if it went away,
and how one measures how much they care.

In the Developing and Maintaining Software panel, there was some discussion on
this topic: what does sustainability mean? It was pointed out that OSS Watch
proposes a Software Sustainability Maturity Model to address the issue of how
sustainability a particular element of software is, and says that this
sustainability is important. ``When choosing software for procurement or
development reuse - regardless of the license and development model you will
use - you need to consider the future. While a software product may satisfy
today's needs, will it satisfy tomorrow's needs? Will the supplier still be
around in five years' time? Will the supplier still care for all its customers
in five years' time? Will the supplier be responsive to bug reports and feature
requests? In other words, is the software sustainable?''~\cite{OSS-ssmm-web}

Attendees suggested that a key question that the definition of sustainability
is one issue on which the community needs to agree, and that ideally, an
initial definition would be determined during the workshop, or at least some
progress would be made towards this goal.  Another topic that came up is what
the goal of sustainability is.  Perhaps it is reproducible science, or
persistence, or quality, or something else.  Similarly, some attendees want to
understand how success in sustainability is measured.  How does a group of
developers know when they have actually achieved sustainable software? This led
to a comment that sustainability should be addressed throughout the full
software life cycle.

Another topic that came up during the Developing and Maintaining Software panel
is the relationship of sustainability to other software attributes.  Attendees
asked ``what is the relationship between sustainability and provenance?'' And,
``is usability separate from sustainability or a fundamental part of it?''

In addition, the Policy panel had a large amount of discussion about defining
sustainability, as one of the subtopics in that panel was Modeling
Sustainability, and modeling requires defining what will be modeled.

In this subtopic, two papers included discussion of the definition of
sustainability.  Venters et al.~\cite{Venters_WSSSPE} mentioned that this is a
rather ambiguous concept, and that the lack of an accepted definition gets in
the way of integrating the concept into software engineering. They suggest that
sustainability is a non-functional requirement, and that the quality of
software architectures determines sustainability.  They then propose that
sustainability is a measure of a set of central quality attributes:
extensibility, interoperability, maintainability, portability, reusability, and
scalability. Finally, they develop an architecture evaluation framework based
on scenarios that help to illuminate how to measure quality or sustainability
at the architectural level.

Katz and Proctor~\cite{Katz_WSSSPE} included a set of questions that could be
used to measure software sustainability, and though these questions might
falsely lead to yes or no answers, the complete set would determine a range of
values for sustainability. These questions are:
\begin{itemize}
\item Will the software continue to provide the same functionality in the future, 
      even if the environment (other parts of the infrastructure) changes?
\item Is the functionality and usability clearly explained to new users? 
\item Do users have a mechanism to ask questions and to learn about the element?
\item Will the functionality be correct in the future, even if the environment changes?
\item Does it provide the functionality that existing and future users want?
\item Does it incorporate new science/theory/tools as they develop?
\end{itemize}

Lenhardt~\cite{lenhardt-wssspe1-panel} summarized the contributions of the
Modeling Sustainability papers in the panel. As shown in
Table~\ref{tab:defining-sustainability}, for each paper he discussed what
software meant, whether there was a definition of sustainability, and what the
approach was to either understand or evaluate sustainability.

\begin{table}[t]
  \begin{scriptsize}
    \begin{center}
      \caption{Summary of Modeling Sustainability papers from Policy Panel.  Adapted from \cite{lenhardt-wssspe1-panel}.}
      \label{tab:defining-sustainability}
      \begin{tabular}{|p{2.3cm}|p{3.6cm}|p{4.4cm}|p{4.8cm}|}
                \hline
{\bf Paper/Authors}
& {\bf Software}
& {\bf Sustainability}
& {\bf Approach to Understand or Evaluate Sustainability} \\
                \hline
Calero, et al. \cite{Calero_WSSSPE}
& General notion of software. Not explicitly defined.
& Sustainability is linked to quality.
& Add to ISO \\
                \hline
Venters, et al. \cite{Venters_WSSSPE}
& Software as science software; increasingly complex; service-oriented computing
& Extensibility, interoperability, maintainability, portability, reusability, scalability, efficiency
& Use various architecture evaluation approaches to assess sustainability \\
                \hline
Pierce, et al. \cite{Pierce_WSSSPE}
& Cyberinfrastructure software
& Sustainable to the extent to which there is a community to support it
& Open community governance \\
                \hline
Katz and Proctor \cite{Katz_WSSSPE}
& E-research infrastructures (i.e. cyberinfrastructure)
& Persisting over time, meeting original needs and projected needs
& Equates models for the creation of software with sustaining software \\
                \hline
Lenhardt, et al. \cite{Lenhardt_WSSSPE}
& Broadly defined as software supporting science
& Re-use; reproducible science
& Comparing data management life cycle to software development life cycle \\
                \hline
Weber, et al. \cite{Weber_WSSSPE}
& Software broadly defined; a software ecosystem
& Software niches
& Ecological analysis and ecosystem \\
                \hline
     \end{tabular}
    \end{center}
  \end{scriptsize}
\end{table}


Finally, in the workshop's closing session, one of the discussion topics was
what success would look like for the set of WSSSPE activities beyond just the workshop.
One of the answers that was suggested was
having an agreed version of what we mean by sustainability.


\section{Case Studies \note{lead: Ketan Maheshwari, contributors: Andy Terrel}} \label{sec:use-cases}

For the purpose of studying software case studies, we classify the software
projects discussed in the workshop in two broad categories. First, the utility
software, comprising software tools that enable and/or facilitate the
development of other tools and techniques to carry out scientific work. This
includes the software developed to efficiently utilize new research
infrastructures.  Second, the scientific software, comprising software that was
developed with an aim to solve a class of scientific problems. 

These categories have overlap in some cases where case studies do not cleanly
fit into a single category.  Our classification is based on two criteria:
first, the character of a software project that dominates and where it `seems'
to be the best fit, and, second, the workshop discussion session where the
paper about the project was discussed. 

Our discussion is aimed at understanding the practicalities of the points
discussed in the workshop, and we hope to extract the best practices and
associate them with the projects. We discuss how the cases are applicable to
and have impacted user communities over their lifetime, isolating similarities
and differences between projects. We discuss the takeaways for a new
project and the lessons learned. We try to understand how the course of current
and future development projects might be altered to implement lessons learned. 

\subsection{Utility Software}
Utility software has the potential of the broadest community impact of the two
categories. This is especially relevant in the modern era of social computing.
In the context of research, a utility software project could be defined as
general purpose software applicable to one or many generic tasks and/or
enabling other software to run by providing a suitable environment. Examples
are collaborative development frameworks such as \emph{GitHub} and
\emph{Bitbucket}, workflow and scripting frameworks such as \emph{Galaxy},
\emph{Swift}, \emph{Globus} and \emph{VisTrails}, and visualization frameworks
such as \emph{VisIT}. Often projects start with a specific, small set of
requirements and users in mind but expand to provide more generic functionality
and appeal to a wider user community. Owing to its generic nature, utility
software finds a wider user community which in turn leads to a higher
participation in development. Consequently, the process becomes user-driven and
self-sustaining.

Software developed in such a scenario often benefits from
community driven development, deployment and maintenance best practices. One
such example is the \emph{Galaxy} project. It follows agile software
development practices and implements standard practices such as test-driven
development and socialized bug managing practices via \emph{trello}. Galaxy
\emph{histories} and \emph{toolshed} offers easy community sharing of data and
tools further promoting a collaborative environment. The project very closely
follows the guidelines described in~\cite{Carver_WSSSPE} and many
from~\cite{Prlic_WSSSPE}. 

Utility software is often developed aimed at better utilizing particular, new
infrastructures and architectures, e.g., \emph{MVAPICH}, \emph{VisIT}.
Development in many cases is often a high risk/reward undertaking and explores
uncharted territories. 
%
%\note{Dan: so is the only difference here that this category is aimed at new systems, where utility software is not?  If so, perhaps this should be incorporated into that subsection, so there would just be two subsections.  Something in the framing of this subsection doesn't feel right to me.  FL: I respectfully disagree the the only reason to develop frameworks is to better utilize (new or old) infrastructure. Another really important reason is to modularize development, making it much easier for an individual developer/user to integrate their own code. Ketan: I think in this section I wanted to bring up a class of software projects which are undertaken with the main aim of tackling new systems and architectures in mind. New infrastructures such as GPU, Cloud, fast IB, federal science networks, etc. were on my mind as I see many submissions around them in the workshop.}
%
Successful projects reap high rewards and have longer usage span. Long
requirement-development-test cycles.  Wide community support but tends to be
handled by specialists rather then end users. Promotes collaborations across
the breadth (e.g., different departments) and depth (e.g., stakeholders within
a department) of community, one of the key ingredient of a sustainable process.
Ferenbaugh~\cite{Ferenbaugh_WSSSPE} discusses the risks and challenges
associated with software projects dealing with new architectures. To leverage
the power of accelerators such as GPUs and MICs new code and libraries are
required. The experience of efforts as described in~\cite{Ferenbaugh_WSSSPE}
met with a limited success but nonetheless with many invaluable lessons were
learned about influential cultural and technical aspects in sustainable
software development practices.

Another paradigm in utility software is the software delivered as service over
the web. With increasing popularity of cloud-based computational environments,
many users are leaning towards tools used as service. \emph{GitHub} and
\emph{Bitbucket} can be arguably considered to be such tools, catering to
collaborative development. For scientific users \emph{Globus}-based tools are
a case of service-based utility software discussed during the workshop. The
data movement, authentication and sharing services offered by Globus can be
easily used over the web by collaborating researchers.

\subsection{Scientific software}
Scientific software consists primarily of special-purpose software that was
developed for a target use-case scenario or fixed/frozen requirements in mind.
Software projects pertaining to specific scientific domain often tend to be in
a niche and the user community tends to be small to medium. Specific
requirements such as numerical accuracy and algorithmic optimization are some
of the paramount requirements of most scientific software. The resulting
codebase is relatiely small. A smaller codebase and fixed requirements result
in stability, ease of installation, and configurability. Many such projects are
treated as libraries used into larger systems such as some of the utility
software discussed in the previous section. While the software can stay stable
and require relatively low maintenance, the responsibility is often on the
shoulders of a very few developers. Community participation in the development
tends to be low. Development is linear and simplistic with a limited scope to
follow software best practices. Domain science oriented software is developed
to solve  specific problems, e.g., \emph{DUNE}, \emph{PETSc},
\emph{MINRES-QLP}, \emph{FASTMath}. Sustainability of such software is often a
significant challenge. Many submissions reported the software is considered a
`byproduct' of the actual research.  Others contended that the software was not
the main funded part of their research. One exception was \emph{Kitware}, which
while being a software product specializing in the scientific process, has a
core focus of developing communities around software processes. One example of
this process is the development of the \emph{CMake} build utility, which
started out as a building tool for \emph{ITK} but grew to become a generic
build utility for C++ projects. 

%Summary of above discussed cases: lessons, trends, commonalities, is there an ideal sustainability scenario?

\note{Dan: I think there's some overlap
  between this and the discussion in the Developing and Support
  Software section.  Perhaps this should go in the cross-cutting
  issues section?  Let's write it down here - then we can decide if it goes elsewhere}
\note{Ketan: yes, may be this section will split and merge into other sections}

\section{Conclusions} \label{sec:conclusions}

\todo{pull the discussion together}

\todo{add some analysis of the deficiencies and difficulties that are
  present in different fields, and those that are common?}

\todo{say something about licensing - lessons, advice, etc.?}

\subsection{Recommendations or Lessons}

\note{if needed.}

\subsection{Follow up actions}

\note{or at least the discussion about them, and the current plans for
  future events.}

\note{conclusions from pre-workshop paper follows}

The WSSSPE workshop has begun an experiment in how we can
collaboratively build a workshop agenda. However, contributors also
want to get credit for their participation in the process. And the
workshop organizers want to make sure that the workshop content and
their efforts are recorded.  Ideally, there would be a service that
would be able to index the contributions to the workshop, serving the
authors, the organizers, and the larger community. But since there
isn't such a service today, the workshop organizers are writing this
initial report and making use of arXiv as a partial solution to
provide a record of the workshop.

After the workshop, one or more additional papers will be created that
will include the discussions at the workshop. These papers will likely
have many authors, and may be submitted to peer-reviewed journals.


\section*{Acknowledgments}

\todo{anyone who needs to put something in here should}

Some of the work by Katz was
supported by the National Science Foundation while working at the
Foundation; any opinion, finding, and conclusions or recommendations
expressed in this material are those of the author(s) and do not
necessarily reflect the views of the National Science Foundation.


\appendix
\section{List of attendees \note{lead: Shel Swenson}}


The following is a partial list of attendees who were recorded on the
Google doc~\cite{WSSSPE1-google-notes} that was being used for live note taking at the workshop, or by the SC13 student volunteers, with some additions also made by the authors of this report.


\begin{multicols}{3}
\setlength{\parindent}{0pt}
%in theory, should save the old value then set it back after this section, but since this is the end...

Jay Alameda

Gabrielle Allen

David Andrs

Brian Austin

Lorena A. Barba

David Bernholdt

Phil Bourne

Karl Broman

Sharon Broude Geva

Jed Brown

Maxine Brown

David Bruhwiler

Bruno Bzeznik

Alexandru Calotoiu

Jeffrey Carver

Shreyas Cholia

Peng Huat Chua

Neil Chue Hong %surname is Chue Hong, this is the correct order.

John W. Cobb

Timothy Cockerill

Karen Cranston

Rion Dooley

Anshu Dubey

Marat Dukhan

Ian Foster

Juliana Freire

Jeffrey Frey

Derek Gaston

Allison Gehrke

Brian Glendenning

Christian Godenschwager

Derek Groen

Edmund Hart

Magne Haveraaen

Steven Heaton

Oscar Hernandez

James Hetherington

Simon Hettrick

Jonathan Hicks

Kenneth Hoste

James Howison

Daisie Huang

Shao-Ching Huang

Tsutomu Ikegami

Kaxuya Ishimura

Christian Iwainsky

Craig Jackson

Wesley Jones

Randall Judd

Shusuke Kasamatsu

Daniel S. Katz

Kerk Kee

Kellie Kercher

Mads Kristensen

Carolyn Lauzon

Arnaud Legrand

Chris Lenhardt

Michael Levy

Frank L\"{o}ffler

Monica L\"{u}cke

Simon A. F. Lund

Arthur Maccabe

Paul Madden

Louis Maddox

Philip Maechling

Ketan Maheshwari

Brian Marker

Suresh Marru

Cezary Mazurek

James McClure

Matt McKenzie

Chris Mentzel

Paul Messina

Mike Mikailov

J. Yates Monteith

Reagan More

Rafael Morizawa

Pierre Neyron

Lucas Nussbaum

Patrick O'Leary

Manish Parashar

Cody Permann

Jack Perdue

John Peterson

Quan Pham

Marlon Pierce

Heather Piwowar

David Proctor

Sara Rambacher

Nicolas Renon

Jason Riedy

Todd Rimer

Bill Sacks

Andreas Schreiber

William Scullin

Andrew Slaughter

Jaraslaw Slawinski

Arfon Smith

Spencer Smith

James Spencer

Eric Stahlberg

Timothy Stitt

Hyoshin Sung

Fr\'{e}d\'{e}ric Suter

Shel Swenson

Yoshio Tanaka

Andy Terrel

George  Thiruvathukal

Keren Tomko

John Towns

Erik Trainer

Satori Tsuzuki

Matthew Turk

Eric van Wyk

Colin C. Venters

Brice Videau

Tajendra Vir Singh

Von Welch

Nancy Wilkins-Diehr

Theresa Windus

Felix Wolf

Rich Wolski

Lynn Zentner

\end{multicols}



\bibliographystyle{unsrt}

\bibliography{wssspe}
\end{document}
